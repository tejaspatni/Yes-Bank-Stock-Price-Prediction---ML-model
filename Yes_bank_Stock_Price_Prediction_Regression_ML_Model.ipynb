{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "7wuGOrhz0itI",
        "pEMng2IbBLp7",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaspatni/Yes-Bank-Stock-Price-Prediction---ML-model/blob/main/Yes_bank_Stock_Price_Prediction_Regression_ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes Bank Limited is an Indian private sector bank headquartered in Mumbai, India and was founded by Rana Kapoor and Ashok Kapur in 2004. It offers wide range of differentiated products for corporate and retail customers through retail banking and asset management services. On 5 March 2020, in an attempt to avoid the collapse of the bank, which had an excessive amount of bad loans, the Reserve Bank of India (RBI) took control of it.\n",
        "To determine the yes bank stock value on national stock exchange by making the machine learning model of regression. The efficient market hypothesis recommends that the stock cost mirror all right now accessible data and any value change that are not founded on a recently uncovered data subsequently are unpredictable. We have to build a model that predicts the stock's future price."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/tejaspatni/Yes-Bank-Stock-Price-Prediction---ML-model"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month. The main objective is to predict the stockâ€™s closing price of the month."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from datetime import datetime\n",
        "sns.set()\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "data = pd.read_csv('/content/data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "1tMnJV8KCFAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(data[data.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset consists of the yes bank stock price monthly data and having 5 different column which is date,open price,high price,low price and close price.\n",
        "\n",
        "1. The shape of our dataset is 185 rows and 5 columns\n",
        "2. The dataset having no duplicate or missing values.\n",
        "3. Datatype of Date is given as object which we need to change that to DateTime\n",
        "4. Yes bank stock listed on month of july 2005.We have data available from july 2005 to november 2020"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "data.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Date**: In our data its monthly observation of stock since it listed.\n",
        "2. **Open**: The price a stock when the stock exchange open for the day.\n",
        "3. **High**: The maximum price of a stock attain during given period of time.\n",
        "4. **Low**: The minimum price of a stock attain during given period of time.\n",
        "5. **Close**: The price of a stock when the stock exchange closed for the day.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "data.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df = data.copy()\n",
        "df['Date'] = df['Date'].apply(lambda x: datetime.strptime(x, '%b-%y'))\n",
        "df"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "FRyPuCCLXNvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we manipulated the dates to the format accoding to datetime.\n",
        "The insights we get that from 2005 , the stock prices increases till 2018 and afterward there is sharp decline in the prices because of the fraud case."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 - Line chart for Stock price variation (Bivariate)"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Features = list(set(df.columns)-{'Date'})\n",
        "Features"
      ],
      "metadata": {
        "id": "PpU2C62SSYAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "for col in Features:\n",
        "\n",
        "# Create the line chart\n",
        "  sns.lineplot(x= df['Date'],y= df[col])\n",
        "\n",
        "# Add axis labels\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel(col) \n",
        "\n",
        "# Show the chart\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I suggested a line chart as it is a common and effective way to represent trends and patterns in data over time or a sequence of data points. It can visually show how a variable changes over a continuous period, making it useful for time-series data or any data that has a natural ordering. They are simple to understand, and the patterns or trends in the data are easily interpreted.\n",
        "Overall, line charts are a versatile and useful tool for data visualization and analysis, and that is why I picked it as an option for representing data."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the Charts having stock price produces almost same result with little or no variation of price during that day."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights generated were as expected since the price value graph should vary according to the day's price and creating the same graphs for each variable.\n",
        "From this, we can say that there is very less variation of price during the day."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 - Scatter Plot for linearity Check"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_Features = list(set(df.columns)-{'Date','Close'})\n",
        "num_Features"
      ],
      "metadata": {
        "id": "hRiVOzf8n92U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "for col in num_Features:\n",
        "\n",
        "# Create the line chart\n",
        "  sns.scatterplot(x= df['Close'],y= df[col])\n",
        "\n",
        "# Add axis labels\n",
        "  plt.xlabel('Close')\n",
        "  plt.ylabel(col) \n",
        "\n",
        "# Show the chart\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scatter charts are a great choice for visualizing the relationship between two variables, especially when you want to see how one variable is affected by the other. They are useful when you want to see whether there is a correlation or pattern between two variables or whether there are any outliers in the data.\n",
        "scatter charts are a powerful visualization tool that can help you quickly identify patterns, outliers, distributions, and trends in your data."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the chart here define a relationship of dependent with independent variables and it can conclude that all of them are linearly plotted with the dependent variable. "
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It helps to identify the pattern as independent variables are linearly plotted and positively correlated with the dependent variable and the intercept form for this regression is clsoe to zero."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 - Distribution Plot"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "for col in Features:\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.distplot(df[col], color='green')\n",
        "    plt.title(\"Distribution\", fontsize=16)\n",
        "    plt.xlabel(col, fontsize=12)\n",
        "    plt.ylabel('Density', fontsize=12)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution charts, also known as density plots or histograms, are a great choice for visualizing the distribution of data. They show how the data is spread out over a range of values, and can help you identify the shape of the distribution, the presence of outliers, and the location of the center of the data."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the charts are right skewed so that it means thats we have to apply a log transformation to make the distribution as normal and there are some possiblities of the outliers."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, understanding the density chart can help in creating a positive business impact, we can say that the stock was around 40Rs to 100Rs most of the time and this could have been a good time to invest and was in 350Rs just a few times, so selling the stock at 350Rs range can be a good idea"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 - Box Plot"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "for col in Features:\n",
        "  plt.figure(figsize=(15,5))\n",
        "  plt.subplot(1,2,1)\n",
        "  sns.boxplot(y=df[col]) \n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plots are a great choice for visualizing the distribution of data, especially when you want to compare the distributions of two or more groups. They are useful for showing the range, median, and quartiles of a dataset, and can help you identify outliers and compare the spread of data between groups."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Box plot helps us to determine the outlier but in this case the price of the stock went high than its usual range and showing the values of the prices in outliers."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it will create a positive business impact as we can see that the price is going very high as compared to usual range so the stock is going in the overbought region and needs to sell. The fraud case helps to lower down the range of the stock and creted a median of around 50rs."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "dataset = df.drop(['Date'],axis = 1)\n",
        "corr=dataset.corr()\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.heatmap(corr, annot = True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmaps are a powerful visualization tool that can help you visualize relationships, identify patterns and trends, cluster data, and visualize large and complex datasets. They are particularly useful when you have a large number of variables or when you want to see patterns and relationships between multiple variables in a dataset."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the Heatmap, we can say that collinearity between Close and independent variable are high and it is positive impact on the model but the collinearity between independent variable are not good for the model and it is showing very high collinearity between independent variables."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(dataset)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pair plots, also known as scatterplot matrices, are a great choice for visualizing the relationships between multiple variables in a dataset. They allow you to see scatterplots of all possible pairs of variables in a single figure, making it easy to identify patterns and relationships between variables."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a scatter plot with each variable making the visuals easy to check the linearity of the dependent and independent variable."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there is no missing values in the dataset, we are not applying any imputation techniques."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Independent_variable = dataset.drop(['Close'], axis =1)\n",
        "Dependent_variable = dataset['Close']"
      ],
      "metadata": {
        "id": "Ht2DQHCM_eFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating VIF\n",
        "def calc_vif(X):\n",
        "\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(Independent_variable)"
      ],
      "metadata": {
        "id": "1f4PZZ2N6yGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation Inflation Factor. VIF measures how much the variance of an estimated regression coefficient is increased due to multicollinearity in the model. A high VIF value indicates that the variance of the coefficient estimate is inflated due to multicollinearity, which means that the coefficient estimate is less reliable.\n",
        "Therefore, VIF is used to detect and quantify the extent of multicollinearity in a regression model."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though we have high VIF scores, we will not perform feature engineering because for this particular case as each feature is important. In the real world, most indicators take into account each of these features to predict future values."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the data needs to be transformed because it has not normally distributed and right skewed. So to make then distributed normally, we use log transformation"
      ],
      "metadata": {
        "id": "GjDvIhNgFOJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "x = np.log10(Independent_variable)\n",
        "y = np.log10(Dependent_variable)"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in Features:\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    fig = sns.distplot(np.log10(dataset[var]))\n",
        "    fig.set_ylabel(' ')\n",
        "    fig.set_xlabel(var)"
      ],
      "metadata": {
        "id": "KnF6EUw1F9C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train, X_test, y_train, y_test = train_test_split( x,y , test_size = 0.2, random_state = 365) \n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A split of 80-20 % is done on Trian and Test respectively, beacuse its considered to be optimum split."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "reg = LinearRegression()\n",
        "# Fit the Algorithm\n",
        "reg.fit(X_train,y_train)\n",
        "# Predict on the model\n",
        "reg.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "LCbayu0pO5Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "KN9jVOYEPxaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(10**(y_pred))\n",
        "plt.plot(np.array(10**(y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IYNLbMNrPzy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - Lasso and Ridge Regression"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Using Lasso Regression"
      ],
      "metadata": {
        "id": "SNXJ90W07s4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=0.1 , max_iter= 3000)\n",
        "\n",
        "lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "4AEhvoeYl6TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "x1xhhf_6mGyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred_lasso))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_lasso))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred_lasso)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "XJQaIkH0ma0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso Regression : Actual Vs Predicted**"
      ],
      "metadata": {
        "id": "CjYaA1Tc_vbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.plot(10**(y_pred_lasso))\n",
        "plt.suptitle('Actual Vs. Predicted Close Price: Lasso Regression', fontsize=16)\n",
        "plt.legend(['Actual','Predicted'], fontsize=12)\n",
        "plt.xlabel('No of Test Data', fontsize=12)\n",
        "plt.ylabel('Closing Price', fontsize=12)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "qsqGk3l8_uR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_cv = Lasso(tol=1e-2)\n",
        "parameters = {'alpha':[1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_model_cv = GridSearchCV(lasso_cv, parameters,scoring = 'neg_mean_squared_error', cv = 3, return_train_score=True)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_model_cv.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "0L4oTnwz9mkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_model_cv.best_params_"
      ],
      "metadata": {
        "id": "G7nrSeG067ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso_cv = lasso_model_cv.predict(X_test)"
      ],
      "metadata": {
        "id": "v_lwycVH7Qr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred_lasso_cv))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_lasso_cv))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred_lasso_cv)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "HOwhsASb8Acw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso Regression after CV : Actual Vs Predicted**"
      ],
      "metadata": {
        "id": "KRUrZ_Yl_QHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.plot(10**(y_pred_lasso_cv))\n",
        "plt.suptitle('Actual Vs. Predicted Close Price: Lasso Regression after CV', fontsize=16)\n",
        "plt.legend(['Actual','Predicted'], fontsize=12)\n",
        "plt.xlabel('No of Test Data', fontsize=12)\n",
        "plt.ylabel('Closing Price', fontsize=12)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "pdsDCurlARGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used Cross validation and hyper parameter tuning for avoiding overfiting of the model lasso and better accuracy on test data."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes there is a very good improvement since the accuracy increased tremendiously from 50% to 99%"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Using Ridge Regression"
      ],
      "metadata": {
        "id": "CIbR5UbWTJS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge  = Ridge(alpha=0.1)\n",
        "ridge.fit(X_train,y_train)\n",
        "ridge.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "dmLyV3aRTSrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ridge = ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "omTV_J69XA41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred_ridge))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_ridge))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred_ridge)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "2lGW9TWocRRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Regression : Actual Vs Predicted**"
      ],
      "metadata": {
        "id": "8FKPMcmEdRIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.plot(10**(y_pred_ridge))\n",
        "plt.suptitle('Actual Vs. Predicted Close Price: Ridge Regression', fontsize=16)\n",
        "plt.legend(['Actual','Predicted'], fontsize=12)\n",
        "plt.xlabel('No of Test Data', fontsize=12)\n",
        "plt.ylabel('Closing Price', fontsize=12)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "LheohFmfctk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "fEUPePvzdksK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_cv = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge_cv, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "SGuzDaBJdmCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_regressor.best_params_"
      ],
      "metadata": {
        "id": "0ITLMU7EeKg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ridge_cv = ridge_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "TKojUvjqeTUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred_ridge_cv))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_ridge_cv))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred_ridge_cv)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "KYD8IK87en5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge Regression after CV : Actual Vs Predicted**"
      ],
      "metadata": {
        "id": "-74sSkn7gZiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.plot(10**(y_pred_ridge_cv))\n",
        "plt.suptitle('Actual Vs. Predicted Close Price: Ridge Regression after CV', fontsize=16)\n",
        "plt.legend(['Actual','Predicted'], fontsize=12)\n",
        "plt.xlabel('No of Test Data', fontsize=12)\n",
        "plt.ylabel('Closing Price', fontsize=12)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "JdhtAQwlgEVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "FF46pkL5zeGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used Cross validation and hyper parameter tuning for avoiding overfiting of the model lasso and better accuracy on test data."
      ],
      "metadata": {
        "id": "hDTOgEH50ipR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "6tL5fsL50PHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No There is no such improvement and maintained an accuracy percentage of 99%"
      ],
      "metadata": {
        "id": "smR9On9e1krT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 - Elastic Net Regression"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "elastic = ElasticNet(alpha=0.1,l1_ratio=0.5)\n",
        "elastic_model = elastic.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elastic.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "-NZV-FaqijVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_elastic = elastic.predict(X_test)"
      ],
      "metadata": {
        "id": "rx2_dI25ipm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred_elastic))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_elastic))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred_elastic)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "4xZh9rJRjK0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elastic Net Regresstion : Actual Vs Predicted**"
      ],
      "metadata": {
        "id": "cihgknrcjtKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.plot(10**(y_pred_elastic))\n",
        "plt.suptitle('Actual Vs. Predicted Close Price: Elastic Regression', fontsize=16)\n",
        "plt.legend(['Actual','Predicted'], fontsize=12)\n",
        "plt.xlabel('No of Test Data', fontsize=12)\n",
        "plt.ylabel('Closing Price', fontsize=12)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "yL0KCJi_jkUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "elastic_cv = ElasticNet(tol=1e-1)\n",
        "parameters = {'alpha':[1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100],'l1_ratio':[0.3,0.4,0.5,0.6,0.7,0.8,1]}\n",
        "elastic_model_cv = GridSearchCV(elastic_cv,parameters,scoring='neg_mean_squared_error',cv=5)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elastic_model_cv.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "KAmppzZxoG5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elastic_model_cv.best_params_"
      ],
      "metadata": {
        "id": "iPz9kGvQwAq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_elastic_cv = elastic_model_cv.predict(X_test)"
      ],
      "metadata": {
        "id": "vguQJP3NwCWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(10**(y_test), 10**(y_pred_elastic_cv))\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(10**(y_test), 10**(y_pred_elastic_cv))\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(10**(y_test), 10**(y_pred_elastic_cv)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "iHcAUy98wfTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elastic Net Regresstion after CV: Actual Vs Predicted**"
      ],
      "metadata": {
        "id": "uWsghRcWxAkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(10**(np.array(y_test)))\n",
        "plt.plot(10**(y_pred_elastic))\n",
        "plt.suptitle('Actual Vs. Predicted Close Price: Elastic Regression', fontsize=16)\n",
        "plt.legend(['Actual','Predicted'], fontsize=12)\n",
        "plt.xlabel('No of Test Data', fontsize=12)\n",
        "plt.ylabel('Closing Price', fontsize=12)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "p7YGRemew3Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used Cross validation and hyper parameter tuning for avoiding overfiting of the model lasso and better accuracy on test data."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes there is a good improvement as its accuracy increases from 75% to 98%."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I would like to consider R^2 Evaluation matric for the positove business impact because it helps to find out the accuracy of the model generated and how effective it will be in predicting fuuture values or in decision making"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I would like to choose the simple linear regression model and the ridge regression model because of good prediction accuracy than lasso and Elastic Net and good scores of evalution metrics."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  There is increase in trend of Yes Bank's stock's Close,Open,High,Low price till 2018 and then sudden decrease.\n",
        "*  We observed that open vs close price graph concluded that after 2018 yes bank's stock hitted drastically.\n",
        "*  We saw Linear relation between the dependent and independent values.\n",
        "*  There was alot of multicollinearity present in data.\n",
        "*  Target variable(dependent variable) strongly dependent on independent variables\n",
        "*  We get maximum accuracy of 99%.\n",
        "*  Linear regression and Ridge regression get almost same R squared value\n",
        "*  Lasso model shows lowest R squared value and high MSE,RMSE,MAE,MAPE\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}